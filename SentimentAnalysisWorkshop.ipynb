{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5de47",
   "metadata": {
    "tags": [
     "hide-cell",
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%pip install openai nltk ipywidgets numpy requests-cache backoff\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f29fd",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with ChatGPT\n",
    "\n",
    "Sentiment Analysis is sort of like the \"Hello, world!\" of Natural Language Processing (NLP), but luckily for us, it's a bit more fun than just echoing out a string - otherwise this workshop could be a bit bland.\n",
    "\n",
    "This notebook will guide you through analyzing sentiment with ChatGPT and discuss some of the differences between how you can approach this problem with a generative AI like ChatGPT versus how you might have approached this problem in the past.\n",
    "\n",
    "**Note**: For a better learning experience, this notebook purposely hides some implementation details like how interactive widgets are created and certain imports of notebook-specific utilities. Full details are available if you open this notebook in your editor of choice or expand the hidden cells.\n",
    "\n",
    "## What is sentiment analysis?\n",
    "\n",
    "Sentiment Analysis is a way of analyzing some text to determine if it's positive, negative, or neutral.\n",
    "\n",
    "This is the kind of thing that's pretty easy for a human who understands the language the text is written in, but it can be hard for a computer to really understand the underlying meaning behind the text.\n",
    "\n",
    "### Examples\n",
    "\n",
    "1. \"I saw that movie.\" - Neutral\n",
    "2. \"I love that movie.\" - Positive\n",
    "3. \"I hate that movie.\" - Negative\n",
    "\n",
    "## How do we analyze sentiment?\n",
    "\n",
    "We'll start with some housekeeping first by making sure that our dependencies are ready.\n",
    "\n",
    "For this demo, we'll start out by exploring a more traditional approach that uses the Python Natural Language Toolkit (NLTK) and then we'll see how our approach might change when we use ChatGPT via the OpenAI SDK instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f45b4b3",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "First, we'll import the relevant tools we'll be using in the notebook and configure some global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557e3c67",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import openai\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# globals\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TEMPERATURE = 0.2\n",
    "STORY_SAMPLE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1782d",
   "metadata": {
    "tags": [
     "hide-cell",
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "import ipywidgets as pywidgets\n",
    "import requests as request\n",
    "import requests_cache\n",
    "import backoff\n",
    "\n",
    "# configuration widgets\n",
    "from widgets.config import modelDropdown, apiKeyInput, apiKeyUpdateButton, temperatureSlider, sampleSizeSlider, sampleSizeWarningLabel, openAiHeader, hackerNewsHeader\n",
    "\n",
    "# project-specific widgets\n",
    "from widgets.simple import simpleAnalysisWidget\n",
    "from widgets.advanced import advancedAnalysisWidget, configureOpenAi\n",
    "\n",
    "# project-specific utilities\n",
    "from utils.obfuscate import obfuscateKey\n",
    "\n",
    "# globals\n",
    "REQUEST_CACHE_EXPIRATION_SECONDS = 60 * 15\n",
    "\n",
    "# we'll use this session to cache our hacker news api requests\n",
    "session = requests_cache.CachedSession('hackernews_cache', expire_after=REQUEST_CACHE_EXPIRATION_SECONDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9faba98",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The code cell below renders a configuration form that you can use to adjust some variables used by other cells in this notebook.\n",
    "\n",
    "You can make changes to the configuration form at any time and rerun cells that make requests to the OpenAI API or Hacker News API to see how the results change.\n",
    "\n",
    "You can configure the following values:\n",
    "\n",
    "- **Open AI API Key**: Your [OpenAI API key](https://platform.openai.com/account/api-keys) is read from the `$OPENAI_API_KEY` environment variable if it's set, but you can override it in this notebook. When you click the **Update Key** button the key you entered will be obfuscated and stored in the `OPENAI_API_KEY` global variable.\n",
    "- **Model**: You can choose between the `gtp-3.5-turbo` and `gpt-4` models for this demo. The `gpt-4` model is more powerful, but it's also slower and more expensive to use.\n",
    "- **Temperature**: A model's temperature is a measure of how \"creative\" or \"unique\" it's response will be. You can set this to `0` for something pretty close to deterministic responses to simple queries.\n",
    "- **Sample Size**: We'll be gathering the top storeis from the [Hacker News API](https://github.com/HackerNews/API) and then sending the titles of a sample of those stories to the model for analysis. For quicker, cheaper results you may want to set this to a lower number. The larger your sample, the more tokens that will be consumed and the more likely you are to hit any rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12db0c43",
   "metadata": {
    "tags": [
     "hide-input",
     "thebe-init"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfbac3f0436426396f9b33ce5357b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='OpenAI API', style=LabelStyle(font_size='1.2rem', font_weight='boldâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code cell is just used to display a widget\n",
    "# for us to configure some settings that other cells\n",
    "# in this notebook rely on\n",
    "apiKeyInput.value = obfuscateKey(OPENAI_API_KEY)\n",
    "sampleSizeSlider.value = STORY_SAMPLE_SIZE\n",
    "temperatureSlider.value = TEMPERATURE\n",
    "\n",
    "def updateApiKey(event):\n",
    "  global OPENAI_API_KEY\n",
    "  OPENAI_API_KEY = apiKeyInput.value\n",
    "  apiKeyInput.value = obfuscateKey(OPENAI_API_KEY)\n",
    "\n",
    "def updateSampleSize(change):\n",
    "  global STORY_SAMPLE_SIZE\n",
    "  STORY_SAMPLE_SIZE = change['new']\n",
    "\n",
    "def updateTemperature(change):\n",
    "  global TEMPERATURE\n",
    "  TEMPERATURE = change['new']\n",
    "\n",
    "temperatureSlider.observe(updateTemperature, names='value')\n",
    "sampleSizeSlider.observe(updateSampleSize, names='value')\n",
    "apiKeyUpdateButton.on_click(updateApiKey)\n",
    "\n",
    "apiKeyConfigWidget = pywidgets.HBox([apiKeyInput, apiKeyUpdateButton])\n",
    "openAiConfigWidget = pywidgets.VBox([openAiHeader, apiKeyConfigWidget, modelDropdown, temperatureSlider])\n",
    "hackerNewsConfigWidget = pywidgets.VBox([hackerNewsHeader, sampleSizeSlider, sampleSizeWarningLabel])\n",
    "configWidget = pywidgets.VBox([openAiConfigWidget, hackerNewsConfigWidget])\n",
    "\n",
    "display(configWidget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59708fe",
   "metadata": {},
   "source": [
    "## Simple sentiment analysis with NLTK\n",
    "\n",
    "Let's take a look at a simple example of sentiment analysis with `nltk` and VADER.\n",
    "\n",
    "The `SentimentIntensityAnalyzer` returns an object with positive, negative, and neutral scores for the given text as well as a combined `compound` score computed from the other three.\n",
    "\n",
    "For this basic example, we're going to rely on the `compound` score and use a naive rating scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cec9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the VADER sentiment analyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# instantiate the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# analyze the sentiment of a string of text\n",
    "def analyzeSentiment(text):\n",
    "  if not text:\n",
    "    return('')\n",
    "\n",
    "  # use VADER to get the +/- sentiment of the string\n",
    "  sentiment = analyzer.polarity_scores(text)\n",
    "\n",
    "  # map the sentiment to a human readable label\n",
    "  if sentiment['compound'] >= 0.75:\n",
    "    return('Very Positive')\n",
    "  elif sentiment['compound'] >= 0.4:\n",
    "    return('Positive')\n",
    "  elif sentiment['compound'] >= 0.1:\n",
    "    return('Leaning Positive')\n",
    "  elif sentiment['compound'] <= -0.1 and sentiment['compound'] > -0.4:\n",
    "    return('Leaning Negative')\n",
    "  elif sentiment['compound'] <= -0.4 and sentiment['compound'] > -0.75:\n",
    "    return('Negative')\n",
    "  elif sentiment['compound'] <= -0.75:\n",
    "    return('Very Negative')\n",
    "  else:\n",
    "    return('Neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c621be",
   "metadata": {},
   "source": [
    "Now let's test this analyzer with some example strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94cc9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love that movie. (Positive)\n",
      "I hate that movie. (Negative)\n",
      "I like that movie. (Leaning Positive)\n",
      "I dislike that movie. (Leaning Negative)\n",
      "I saw that movie. (Neutral)\n"
     ]
    }
   ],
   "source": [
    "# some simple test statements for our analyzer\n",
    "statements = [\n",
    "  'I love that movie.',\n",
    "  'I hate that movie.',\n",
    "  'I like that movie.',\n",
    "  'I dislike that movie.',\n",
    "  'I saw that movie.',\n",
    "]\n",
    "\n",
    "for statement in statements:\n",
    "  print(f\"{statement} ({analyzeSentiment(statement)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6429f9",
   "metadata": {},
   "source": [
    "We've wired the input below up to the same analyzer function from above. Type in some text and see how the analyzer responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "342011fc",
   "metadata": {
    "tags": [
     "hide-input",
     "thebe-init"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aba5cd22fd0415cbe8fd5ab9bc79676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Text(value='', placeholder='Type something'), Output()), layout=Layout(align_items='center', disâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code cell is just used to display a widget\n",
    "# that uses the analyzeSentiment function we created\n",
    "display(simpleAnalysisWidget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bbf2a5",
   "metadata": {},
   "source": [
    "## How Sentiment Analysis Works\n",
    "\n",
    "Sentiment analysis, like most text analysis involves a multistep process:\n",
    "\n",
    "1. **Stemming / Lemmatization**: reduces the words in the text to their root forms to simplify comparison between different forms of the same words\n",
    "   1. **Stemming**: removes suffixes as an attempt to reduce words to their root forms\n",
    "   2. **Lemmatization**: uses a morphological analysis of words to reduce them to their root forms\n",
    "2. **Tokenization**: breaks the text into individual units of meaning called tokens\n",
    "3. **Vectorization**: converts the tokens into a id that can be used for comparison\n",
    "4. **Comparison**: compares the tokens to a known set of tokens to determine the sentiment\n",
    "\n",
    "In this case we're taking advantage of an existing model that has been trained to analyze sentiment in text. If we wanted to build our own from scratch, it would be a more complicated process and require training data to feed into the model.\n",
    "\n",
    "With the advent of Generative Pre-Trained Transformer (GPT) models like those that power ChatGPT, and other transformer models that have exploded in popularity since, we can leverage the powerful inference and predictive capabilities of these models to perform sentiment analysis without having to train our own model, and we can even leverage some prompting techniques to quickly teach the model how to perform more unique analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c607a30",
   "metadata": {},
   "source": [
    "## A more interesting example\n",
    "\n",
    "So, let's see how this works with text generated by other humans without knowing that someone would be trying to analyze the sentiment of their text.\n",
    "\n",
    "For this example, we'll pull in a random sample of the [top stories](https://github.com/HackerNews/API#new-top-and-best-stories) on [Hacker News](https://news.ycombinator.com/) and analyze the sentiment of each submission's title.\n",
    "\n",
    "You can run the cell below a few times to generate different samples of the top stories until you find a collection you prefer and then rerun the cells below to use that sample for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62e3462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clorox products in short supply after cyberattack (Neutral)\n",
      "Americans Are Losing Faith in the Value of College. Whose Fault Is That? (Neutral)\n",
      "Researchers gave 200 people $10k each to study generosity (Positive)\n",
      "The path to detecting extraterrestrial life with astrophotonics (Neutral)\n",
      "The Astrologer of the Nineteenth Century (1825) (Neutral)\n"
     ]
    }
   ],
   "source": [
    "# we'll use this Array to aggregate the story titles so we can loop through and analyze them\n",
    "stories = {}\n",
    "\n",
    "# we'll use the request cache session we created earlier to make sure that this response is fast\n",
    "# when the cell runs again - \n",
    "topStoryIdsRequest = session.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n",
    "\n",
    "if topStoryIdsRequest.status_code != 200:\n",
    "  print('There was a problem getting the top stories from Hacker News')\n",
    "  exit()\n",
    "\n",
    "topStoryIds = topStoryIdsRequest.json()\n",
    "\n",
    "storyIds = np.array(topStoryIds)[np.random.choice(len(topStoryIds), STORY_SAMPLE_SIZE, replace=False)]\n",
    "\n",
    "for storyId in storyIds:\n",
    "  # we'll use the same request cache so that we don't have to request a story's details more than once\n",
    "  storyRequest = session.get(f'https://hacker-news.firebaseio.com/v0/item/{storyId}.json')\n",
    "\n",
    "  if storyRequest.status_code != 200:\n",
    "    continue\n",
    "  else:\n",
    "    story = storyRequest.json()\n",
    "\n",
    "    if 'title' in story:\n",
    "      stories[storyId] = {\n",
    "        \"title\": story['title'],\n",
    "        \"time\": story['time'],\n",
    "        \"sentiment\": {\n",
    "          \"nltk\": analyzeSentiment(story['title']),\n",
    "          # we'll be updating the dict with the sentiment from OpenAI later\n",
    "          \"openai\": {}\n",
    "        }\n",
    "      }\n",
    "\n",
    "# iterate through titles and analyze the sentiment\n",
    "for storyId, story in stories.items():\n",
    "  print(f\"{story['title']} ({story['sentiment']['nltk']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d164653f",
   "metadata": {},
   "source": [
    "## How ChatGPT works\n",
    "\n",
    "Break down how ChatGPT turns text into tokens and then predicts the most likely tokens to follow the given text so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc95505",
   "metadata": {},
   "source": [
    "## Prompt engineering\n",
    "\n",
    "Describe prompt engineering and break down system, user, and assistant prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6a510",
   "metadata": {},
   "source": [
    "## Zero shot and few shot prompting\n",
    "\n",
    "Discuss the differences between few show and zero shot and give some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c237a87",
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1694090931628,
     "user": {
      "displayName": "Matthias Kraft",
      "userId": "07587708083169164935"
     },
     "user_tz": -120
    },
    "id": "3c237a87"
   },
   "outputs": [],
   "source": [
    "BASIC_SYSTEM_PROMPT = \"\"\"\n",
    "You are VibeCheck, an advanced AI system for detecting the sentiment conveyed in user-generated text.\n",
    "\n",
    "The user will provide you with a prompt, and you will respond with the sentiment of that prompt.\n",
    "\n",
    "Be concise.\n",
    "\"\"\"\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def basicChatGptSentiment(prompt, model=modelDropdown.value):\n",
    "    messages = [{ \"role\": \"system\", \"content\": BASIC_SYSTEM_PROMPT }]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0e406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clorox products in short supply after cyberattack\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Neutral\n",
      "---\n",
      "Americans Are Losing Faith in the Value of College. Whose Fault Is That?\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Neutral\n",
      "---\n",
      "Researchers gave 200 people $10k each to study generosity\n",
      "NLTK: Positive\n",
      "gpt-3.5-turbo: Positive\n",
      "---\n",
      "The path to detecting extraterrestrial life with astrophotonics\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Exciting and optimistic.\n",
      "---\n",
      "The Astrologer of the Nineteenth Century (1825)\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Neutral\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "if OPENAI_API_KEY:\n",
    "  for storyId, story in stories.items():\n",
    "    sentiment = basicChatGptSentiment(story['title'])\n",
    "    \n",
    "    if modelDropdown.value not in story['sentiment']['openai']:\n",
    "      story['sentiment']['openai'][modelDropdown.value] = {}\n",
    "\n",
    "    story['sentiment']['openai'][modelDropdown.value]['basic'] = sentiment\n",
    "\n",
    "    print(f\"{story['title']}\\nNLTK: {story['sentiment']['nltk']}\\n{modelDropdown.value}: {sentiment}\\n---\")\n",
    "else:\n",
    "  print('Please enter your OpenAI API key above and rerun this cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e479fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADVANCED_SYSTEM_PROMPT = \"\"\"\n",
    "You are VibeCheck, an advanced AI system for detecting the sentiment conveyed in user-generated text.\n",
    "\n",
    "The user will provide you with a prompt, and you will analyze it following these steps:\n",
    "\n",
    "1. Analyze the prompt for relevant emotion, tone, affinity, sarcasm, irony, etc.\n",
    "2. Analyze the likely emotional state of the author based on those findings\n",
    "3. Summarize the emotional state and sentiment of the prompt based on your findings using 5 or less names for emotions using lowercase letters and separating each emotional state with a comma\n",
    "\n",
    "Only return the output from the final step to the user.\n",
    "\"\"\"\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def advancedChatGptSentiment(prompt, model=modelDropdown.value):\n",
    "    messages = [{ \"role\": \"system\", \"content\": ADVANCED_SYSTEM_PROMPT }]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.25,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2aee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clorox products in short supply after cyberattack\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: concerned, frustrated, anxious\n",
      "---\n",
      "Americans Are Losing Faith in the Value of College. Whose Fault Is That?\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: uncertainty, frustration, blame, skepticism\n",
      "---\n",
      "Researchers gave 200 people $10k each to study generosity\n",
      "NLTK: Positive\n",
      "gpt-3.5-turbo: neutral, curious, hopeful\n",
      "---\n",
      "The path to detecting extraterrestrial life with astrophotonics\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: curiosity, excitement, anticipation\n",
      "---\n",
      "The Astrologer of the Nineteenth Century (1825)\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: curiosity, intrigue, fascination\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "if OPENAI_API_KEY:\n",
    "  for storyId, story in stories.items():\n",
    "    sentiment = advancedChatGptSentiment(story['title'])\n",
    "\n",
    "    if modelDropdown.value not in story['sentiment']['openai']:\n",
    "      story['sentiment']['openai'][modelDropdown.value] = {}\n",
    "\n",
    "    story['sentiment']['openai'][modelDropdown.value]['advanced'] = sentiment\n",
    "\n",
    "    print(f\"{story['title']}\\nNLTK: {story['sentiment']['nltk']}\\n{modelDropdown.value}: {sentiment}\\n---\")\n",
    "else:\n",
    "  print('Please enter your OpenAI API key above and rerun this cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59daa29b",
   "metadata": {
    "tags": [
     "hide-input",
     "thebe-init"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d445c7eebf045d8a7f2f7df36fb6b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', placeholder='Type something'), Button(button_style='primary', desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code cell is just used to display a widget\n",
    "# that uses the analyzeSentiment function we created\n",
    "# as well as the advancedChatGptSentiment function\n",
    "configureOpenAi(OPENAI_API_KEY, modelDropdown.value)\n",
    "\n",
    "display(advancedAnalysisWidget)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
