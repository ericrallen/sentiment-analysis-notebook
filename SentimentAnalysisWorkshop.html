

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Sentiment Analysis with ChatGPT &#8212; Sentiment Analysis</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'SentimentAnalysisWorkshop';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="#">
  
  
  
  
  
    <p class="title logo__title">Sentiment Analysis</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1 current active">
                <a class="reference internal" href="#">
                    Sentiment Analysis with ChatGPT
                </a>
            </li>
        </ul>
        
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/ericrallen/sentiment-analysis-notebook/main?urlpath=tree/SentimentAnalysisWorkshop.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>



<a href="https://github.com/ericrallen/sentiment-analysis-notebook" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/SentimentAnalysisWorkshop.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Sentiment Analysis with ChatGPT</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-sentiment-analysis">What is sentiment analysis?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#initial-setup">Initial Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration">Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-sentiment-analysis-with-nltk">Simple sentiment analysis with NLTK</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How it works</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learn-more">Learn more</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language-models">Language models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-example">Real world example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt">ChatGPT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-chatgpt-works">How ChatGPT works</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokens">Tokens</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering">Prompt engineering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-conversation-document">Example conversation document</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-example">Basic example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#going-further">Going further</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-tools">Comparison of tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beyond-sentiment">Beyond sentiment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompting-strategies">Prompting strategies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learn-more-about-prompting-strategies">Learn more about prompting strategies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-shot-prompting">One shot prompting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#few-shot-prompting">Few shot prompting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-approaches">Comparing approaches</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gathering-our-data">Gathering our data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sentiment-analysis">Sentiment analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#emotion-analysis">Emotion analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Prompting strategies</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="cell tag_hide-cell tag_thebe-init docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>

<span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">openai</span> <span class="n">nltk</span> <span class="n">ipywidgets</span> <span class="n">numpy</span> <span class="n">requests</span><span class="o">-</span><span class="n">cache</span> <span class="n">backoff</span> <span class="n">tiktoken</span> <span class="n">nrclex</span> <span class="n">pandas</span>
</pre></div>
</div>
</div>
</details>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="sentiment-analysis-with-chatgpt">
<h1>Sentiment Analysis with ChatGPT<a class="headerlink" href="#sentiment-analysis-with-chatgpt" title="Permalink to this heading">#</a></h1>
<p>While sentiment analysis is sort of like the <a class="reference external" href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program#Variations">“Hello, world!”</a> of <a class="reference external" href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> (NLP), luckily for us it’s a bit more fun than just echoing out a string.</p>
<p>This notebook will introduce you to sentiment analysis using traditional NLP tools and then explore analyzing sentiment with <a class="reference external" href="https://openai.com/blog/chatgpt">ChatGPT</a>.</p>
<p><strong>Note</strong>: For a better learning experience, this notebook contains some code cells that are only used to render widgets for you to interact with and some others that only generate data structures or variables that later cells will reference.</p>
<section id="what-is-sentiment-analysis">
<h2>What is sentiment analysis?<a class="headerlink" href="#what-is-sentiment-analysis" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> is a way of analyzing some text to determine if it’s positive, negative, or neutral.</p>
<p>This is the kind of thing that’s pretty easy for a human who understands the language the text is written in to do, but it can be hard for a computer to really understand the underlying meaning behind the language.</p>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>“I saw that movie.” (neutral)</p></li>
<li><p>“I love that movie.” (positive)</p></li>
<li><p>“I hate that movie.” (negative)</p></li>
</ul>
</section>
</section>
<section id="initial-setup">
<h2>Initial Setup<a class="headerlink" href="#initial-setup" title="Permalink to this heading">#</a></h2>
<p>First, we’ll import the relevant tools we’ll be using in the notebook and configure some global variables.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nltk</span></code>: Python’s <a class="reference external" href="https://www.nltk.org/">Natural Language Toolkit</a>, which we’ll use to explore some more traditional sentiment analysis techniques</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openai</span></code>: Python library for interacting with the <a class="reference external" href="https://platform.openai.com/docs/api-reference/introduction">OpenAI API</a></p></li>
</ul>
<p><strong>Note</strong>: In a later cell, we’ll also make use of <a class="reference external" href="https://github.com/metalcorebear/NRCLex"><code class="docutils literal notranslate"><span class="pre">nrclex</span></code></a> to investigate some more advanced NLP, but because it’s only used in one cell, we’re importing it there for clarity.</p>
<div class="cell tag_thebe-init docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">openai</span>

<span class="c1"># download nltk data</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;vader_lexicon&quot;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;punkt&quot;</span><span class="p">)</span>

<span class="c1"># globals</span>
<span class="n">OPENAI_API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">)</span>
<span class="n">TEMPERATURE</span> <span class="o">=</span> <span class="mf">0.37</span>
<span class="n">STORY_SAMPLE_SIZE</span> <span class="o">=</span> <span class="mi">12</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package vader_lexicon to
[nltk_data]     /home/runner/nltk_data...
[nltk_data]   Package vader_lexicon is already up-to-date!
[nltk_data] Downloading package punkt to /home/runner/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
</div>
</div>
<p>You’ll be able to configure these global variables using an embedded widget form below.</p>
<div class="cell tag_hide-cell tag_thebe-init docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this cell focuses on some implemetation details specific to</span>
<span class="c1"># this notebook that aren&#39;t actually important to understand</span>
<span class="c1"># you can just ignore/collapse it if you would prefer</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">pywidgets</span>
<span class="kn">import</span> <span class="nn">requests</span> <span class="k">as</span> <span class="nn">request</span>
<span class="kn">import</span> <span class="nn">requests_cache</span>
<span class="kn">import</span> <span class="nn">backoff</span>

<span class="c1"># configuration widgets</span>
<span class="kn">from</span> <span class="nn">widgets.config</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">modelDropdown</span><span class="p">,</span>
    <span class="n">apiKeyInput</span><span class="p">,</span>
    <span class="n">apiKeyUpdateButton</span><span class="p">,</span>
    <span class="n">temperatureSlider</span><span class="p">,</span>
    <span class="n">sampleSizeSlider</span><span class="p">,</span>
    <span class="n">sampleSizeWarningLabel</span><span class="p">,</span>
    <span class="n">openAiHeader</span><span class="p">,</span>
    <span class="n">hackerNewsHeader</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># project-specific widgets</span>
<span class="kn">from</span> <span class="nn">widgets.simple</span> <span class="kn">import</span> <span class="n">simpleAnalysisWidget</span>
<span class="kn">from</span> <span class="nn">widgets.advanced</span> <span class="kn">import</span> <span class="n">advancedAnalysisWidget</span><span class="p">,</span> <span class="n">configureOpenAi</span>
<span class="kn">from</span> <span class="nn">widgets.tokens</span> <span class="kn">import</span> <span class="n">tokenAnalysisWidget</span><span class="p">,</span> <span class="n">configureModel</span>

<span class="c1"># project-specific utilities</span>
<span class="kn">from</span> <span class="nn">utils.obfuscate</span> <span class="kn">import</span> <span class="n">obfuscateKey</span>
<span class="kn">from</span> <span class="nn">utils.array</span> <span class="kn">import</span> <span class="n">checkArrayLengths</span>

<span class="c1"># we don&#39;t want to display too many entries in our DataFrames</span>
<span class="c1"># if the sample size is too large</span>
<span class="n">DATAFRAME_LIMIT</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1"># we&#39;ll use this session to cache our hacker news api requests</span>
<span class="n">REQUEST_CACHE_EXPIRATION_SECONDS</span> <span class="o">=</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">15</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">requests_cache</span><span class="o">.</span><span class="n">CachedSession</span><span class="p">(</span>
    <span class="s2">&quot;hackernews_cache&quot;</span><span class="p">,</span> <span class="n">expire_after</span><span class="o">=</span><span class="n">REQUEST_CACHE_EXPIRATION_SECONDS</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Permalink to this heading">#</a></h2>
<p>You can make changes to the configuration form below at any time and rerun cells that make requests to the OpenAI API or Hacker News API to see how the results change.</p>
<p>You can configure the following values:</p>
<ul class="simple">
<li><p><strong>Open AI API Key</strong>: Your <a class="reference external" href="https://platform.openai.com/account/api-keys">OpenAI API key</a> is read from the <code class="docutils literal notranslate"><span class="pre">$OPENAI_API_KEY</span></code> environment variable if it’s set, but you can override it in this notebook; when you click the <strong>Update Key</strong> button the key you entered will be obfuscated and stored in the <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> global variable</p></li>
<li><p><strong>Model</strong>: The <a class="reference external" href="https://platform.openai.com/docs/models">OpenAI model</a> that the demo should use; you can choose between the <code class="docutils literal notranslate"><span class="pre">gtp-3.5-turbo</span></code> and <code class="docutils literal notranslate"><span class="pre">gpt-4</span></code> models for this demo</p></li>
<li><p><strong>Temperature</strong>: A model’s <a class="reference external" href="https://platform.openai.com/docs/guides/gpt/how-should-i-set-the-temperature-parameter">temperature</a> is a measure of how “creative” it’s response will be; you can set this to <code class="docutils literal notranslate"><span class="pre">0</span></code> for something pretty close to deterministic responses to simple queries</p></li>
<li><p><strong>Sample Size</strong>: We’ll be gathering the top stories from the <a class="reference external" href="https://github.com/HackerNews/API">Hacker News API</a> and then analyzing the sentiment of a sample of those stories’ titles; this controls how large that sample is</p></li>
</ul>
<div class="cell tag_hide-input tag_thebe-init docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code cell is just used to display a widget for us to</span>
<span class="c1"># configure some settings that other cells in this notebook rely on</span>
<span class="c1"># you can just ignore/collapse it if you would prefer</span>
<span class="n">apiKeyInput</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">obfuscateKey</span><span class="p">(</span><span class="n">OPENAI_API_KEY</span><span class="p">)</span>
<span class="n">sampleSizeSlider</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">STORY_SAMPLE_SIZE</span>
<span class="n">temperatureSlider</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">TEMPERATURE</span>


<span class="k">def</span> <span class="nf">updateApiKey</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">OPENAI_API_KEY</span>
    <span class="n">OPENAI_API_KEY</span> <span class="o">=</span> <span class="n">apiKeyInput</span><span class="o">.</span><span class="n">value</span>
    <span class="n">apiKeyInput</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">obfuscateKey</span><span class="p">(</span><span class="n">OPENAI_API_KEY</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">updateSampleSize</span><span class="p">(</span><span class="n">change</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">STORY_SAMPLE_SIZE</span>
    <span class="n">STORY_SAMPLE_SIZE</span> <span class="o">=</span> <span class="n">change</span><span class="p">[</span><span class="s2">&quot;new&quot;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">updateTemperature</span><span class="p">(</span><span class="n">change</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">TEMPERATURE</span>
    <span class="n">TEMPERATURE</span> <span class="o">=</span> <span class="n">change</span><span class="p">[</span><span class="s2">&quot;new&quot;</span><span class="p">]</span>


<span class="n">temperatureSlider</span><span class="o">.</span><span class="n">observe</span><span class="p">(</span><span class="n">updateTemperature</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
<span class="n">sampleSizeSlider</span><span class="o">.</span><span class="n">observe</span><span class="p">(</span><span class="n">updateSampleSize</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
<span class="n">apiKeyUpdateButton</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">updateApiKey</span><span class="p">)</span>

<span class="n">apiKeyConfigWidget</span> <span class="o">=</span> <span class="n">pywidgets</span><span class="o">.</span><span class="n">HBox</span><span class="p">([</span><span class="n">apiKeyInput</span><span class="p">,</span> <span class="n">apiKeyUpdateButton</span><span class="p">])</span>
<span class="n">openAiConfigWidget</span> <span class="o">=</span> <span class="n">pywidgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">(</span>
    <span class="p">[</span><span class="n">openAiHeader</span><span class="p">,</span> <span class="n">apiKeyConfigWidget</span><span class="p">,</span> <span class="n">modelDropdown</span><span class="p">,</span> <span class="n">temperatureSlider</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">hackerNewsConfigWidget</span> <span class="o">=</span> <span class="n">pywidgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">(</span>
    <span class="p">[</span><span class="n">hackerNewsHeader</span><span class="p">,</span> <span class="n">sampleSizeSlider</span><span class="p">,</span> <span class="n">sampleSizeWarningLabel</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">configWidget</span> <span class="o">=</span> <span class="n">pywidgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">([</span><span class="n">openAiConfigWidget</span><span class="p">,</span> <span class="n">hackerNewsConfigWidget</span><span class="p">])</span>

<span class="n">display</span><span class="p">(</span><span class="n">configWidget</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "78e6a4593c5e4f7d961c8f6a32dace04"}</script></div>
</div>
</section>
<section id="simple-sentiment-analysis-with-nltk">
<h2>Simple sentiment analysis with NLTK<a class="headerlink" href="#simple-sentiment-analysis-with-nltk" title="Permalink to this heading">#</a></h2>
<p>Let’s take a look at a simple example of sentiment analysis with <code class="docutils literal notranslate"><span class="pre">nltk</span></code> using the <strong>V</strong>alence <strong>A</strong>ware <strong>D</strong>ictionary and s<strong>E</strong>ntiment <strong>R</strong>easoner (<a class="reference external" href="https://vadersentiment.readthedocs.io/en/latest/pages/introduction.html">VADER</a>) module.</p>
<p>VADER’s <code class="docutils literal notranslate"><span class="pre">SentimentIntensityAnalyzer</span></code> returns an object with positive, negative, and neutral scores for the given text as well as a combined <code class="docutils literal notranslate"><span class="pre">compound</span></code> score computed from the other three.</p>
<p>For this basic example, we’re going to rely on the <code class="docutils literal notranslate"><span class="pre">compound</span></code> score and create a naive rating scale that converts that score into a string ranging from <code class="docutils literal notranslate"><span class="pre">very</span> <span class="pre">positive</span></code> to <code class="docutils literal notranslate"><span class="pre">very</span> <span class="pre">negative</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.sentiment.vader</span> <span class="kn">import</span> <span class="n">SentimentIntensityAnalyzer</span>

<span class="n">analyzer</span> <span class="o">=</span> <span class="n">SentimentIntensityAnalyzer</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">convertSentimentToLabel</span><span class="p">(</span><span class="n">sentiment</span><span class="p">):</span>
    <span class="n">sentimentScore</span> <span class="o">=</span> <span class="n">sentiment</span><span class="p">[</span><span class="s2">&quot;compound&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">sentimentScore</span> <span class="o">&gt;=</span> <span class="mf">0.75</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;very positive&quot;</span>
    <span class="k">elif</span> <span class="n">sentimentScore</span> <span class="o">&gt;=</span> <span class="mf">0.4</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;positive&quot;</span>
    <span class="k">elif</span> <span class="n">sentimentScore</span> <span class="o">&gt;=</span> <span class="mf">0.1</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;leaning positive&quot;</span>
    <span class="k">elif</span> <span class="n">sentimentScore</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.1</span> <span class="ow">and</span> <span class="n">sentimentScore</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;leaning negative&quot;</span>
    <span class="k">elif</span> <span class="n">sentimentScore</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.4</span> <span class="ow">and</span> <span class="n">sentimentScore</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;negative&quot;</span>
    <span class="k">elif</span> <span class="n">sentimentScore</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;very negative&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;neutral&quot;</span>


<span class="k">def</span> <span class="nf">analyzeSentiment</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>

    <span class="k">return</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>


<span class="c1"># some simple test statements for our analyzer</span>
<span class="n">statements</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;I love that movie.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;I hate that movie.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;I like that movie.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;I dislike that movie.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;I saw that movie.&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">statement</span> <span class="ow">in</span> <span class="n">statements</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">statement</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">convertSentimentToLabel</span><span class="p">(</span><span class="n">analyzeSentiment</span><span class="p">(</span><span class="n">statement</span><span class="p">))</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>I love that movie. (positive)
I hate that movie. (negative)
I like that movie. (leaning positive)
I dislike that movie. (leaning negative)
I saw that movie. (neutral)
</pre></div>
</div>
</div>
</div>
<p>We’ve wired the input below up to the same analyzer function from above. Type in some text and see how the analyzer responds.</p>
<div class="cell tag_hide-input tag_thebe-init docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code cell is just used to display a widget</span>
<span class="c1"># that uses the analyzeSentiment function we created</span>
<span class="c1"># you can just ignore/collapse it if you would prefer</span>
<span class="n">display</span><span class="p">(</span><span class="n">simpleAnalysisWidget</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "ef88d8f1c3984b34bcd2428aa4aeac38"}</script></div>
</div>
</section>
<section id="how-it-works">
<h2>How it works<a class="headerlink" href="#how-it-works" title="Permalink to this heading">#</a></h2>
<p>Sentiment analysis, like most text analysis involves a multistep process:</p>
<ol class="arabic simple">
<li><p><strong>Stemming / Lemmatization</strong>: reduces the words in the text to their root forms to simplify comparison between different forms of the same words</p>
<ol class="arabic simple">
<li><p><strong>Stemming</strong>: removes suffixes as an attempt to reduce words to their root forms</p></li>
<li><p><strong>Lemmatization</strong>: uses a morphological analysis of words to reduce them to their root forms</p></li>
</ol>
</li>
<li><p><strong>Tokenization</strong>: breaks the text into individual units of meaning called tokens</p></li>
<li><p><strong>Vectorization</strong>: converts the tokens into a id that can be used for comparison</p></li>
<li><p><strong>Comparison</strong>: compares the tokens to a known set of tokens to determine the sentiment</p></li>
</ol>
<p><strong>Note</strong>: This is a simplification of the process to distill it into an easy to digest format, but it is not a full picture and doesn’t include the data gathering, cleaning, and labeling or actual training process.</p>
<section id="learn-more">
<h3>Learn more<a class="headerlink" href="#learn-more" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://thepythoncode.com/article/tokenization-stemming-and-lemmatization-in-python">Tokenization, Stemming, and Lemmatization in Python</a></p></li>
<li><p><a class="reference external" href="https://stackabuse.com/python-for-nlp-tokenization-stemming-and-lemmatization-with-spacy-library/">Python for NLP: Tokenization, Stemming, and Lemmatization with SpaCy Library</a></p></li>
<li><p><a class="reference external" href="https://www.machinelearningplus.com/nlp/what-is-tokenization-in-natural-language-processing/">What is Tokenization in Natural Language Processing (NLP)?</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/understanding-nlp-word-embeddings-text-vectorization-1a23744f7223">Understanding NLP Word Embeddings — Text Vectorization</a></p></li>
</ul>
</section>
<section id="language-models">
<h3>Language models<a class="headerlink" href="#language-models" title="Permalink to this heading">#</a></h3>
<p>In this case we’re taking advantage of an existing <a class="reference external" href="https://en.wikipedia.org/wiki/Language_model">language model</a>, VADER, that has been trained to analyze sentiment in text, but if we wanted to train our own model, it would be a much more involved process.</p>
<p>With the advent of <a class="reference external" href="https://en.wikipedia.org/wiki/Large_language_model">Large Language Models</a> (LLMs), like the <a class="reference external" href="https://en.wikipedia.org/wiki/Generative_pre-trained_transformer">Generative Pre-Trained Transformer</a> (GPT) models that power ChatGPT - and the various <a class="reference external" href="https://informationisbeautiful.net/visualizations/the-rise-of-generative-ai-large-language-models-llms-like-chatgpt/">other models that have exploded in popularity</a> since - we can leverage the powerful inference and predictive capabilities of these models to perform tasks like sentiment analysis with greater accuracy without having to train our own models.</p>
<p>We can even leverage some prompting techniques - which we’ll explore in later cells - to quickly teach the model how to perform more unique analyses and refine our results.</p>
</section>
</section>
<section id="real-world-example">
<h2>Real world example<a class="headerlink" href="#real-world-example" title="Permalink to this heading">#</a></h2>
<p>Let’s take a look at how this works with text generated by other humans (<em>probably</em>) without expecting someone would be trying to analyze the sentiment of their text.</p>
<p>For this example, we’ll pull in a random sample of the <a class="reference external" href="https://github.com/HackerNews/API#new-top-and-best-stories">top stories</a> on <a class="reference external" href="https://news.ycombinator.com/">Hacker News</a> and analyze the sentiment of each submission’s title.</p>
<p>You can run the cell below a few times to generate different samples of the top stories until you find a collection you prefer and then rerun the cells after it to use that sample for the rest of the notebook.</p>
<p><strong>Note</strong>: You can use the configuration widget above to adjust your sample size to find the collection of data that feels right to you.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">sampleStories</span><span class="p">(</span><span class="n">sampleSize</span><span class="o">=</span><span class="n">STORY_SAMPLE_SIZE</span><span class="p">):</span>
    <span class="n">topStoryIdsRequest</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="s2">&quot;https://hacker-news.firebaseio.com/v0/topstories.json&quot;</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">topStoryIdsRequest</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;There was a problem getting the top stories from Hacker News&quot;</span><span class="p">)</span>
        <span class="n">exit</span><span class="p">()</span>

    <span class="n">topStoryIds</span> <span class="o">=</span> <span class="n">topStoryIdsRequest</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="n">storyIds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">topStoryIds</span><span class="p">)[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">topStoryIds</span><span class="p">),</span> <span class="n">sampleSize</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="k">return</span> <span class="n">storyIds</span>


<span class="k">def</span> <span class="nf">getStoryDetails</span><span class="p">(</span><span class="n">storyId</span><span class="p">):</span>
    <span class="c1"># we&#39;ll use the same request cache so that we don&#39;t have to request a story&#39;s details more than once</span>
    <span class="n">storyRequest</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;https://hacker-news.firebaseio.com/v0/item/</span><span class="si">{</span><span class="n">storyId</span><span class="si">}</span><span class="s2">.json&quot;</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">storyRequest</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There was a problem getting story </span><span class="si">{</span><span class="n">storyId</span><span class="si">}</span><span class="s2"> from Hacker News&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">story</span> <span class="o">=</span> <span class="n">storyRequest</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">story</span>


<span class="k">def</span> <span class="nf">getStories</span><span class="p">(</span><span class="n">storyIds</span><span class="p">):</span>
    <span class="n">stories</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">storyId</span> <span class="ow">in</span> <span class="n">storyIds</span><span class="p">:</span>
        <span class="n">story</span> <span class="o">=</span> <span class="n">getStoryDetails</span><span class="p">(</span><span class="n">storyId</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;title&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">:</span>
            <span class="n">stories</span><span class="p">[</span><span class="n">storyId</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">],</span>
                <span class="s2">&quot;time&quot;</span><span class="p">:</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">],</span>
                <span class="s2">&quot;sentiment&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;vader&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;nrclex&quot;</span><span class="p">:</span> <span class="p">{},</span> <span class="s2">&quot;openai&quot;</span><span class="p">:</span> <span class="p">{}},</span>
            <span class="p">}</span>

    <span class="k">return</span> <span class="n">stories</span>


<span class="n">stories</span> <span class="o">=</span> <span class="n">getStories</span><span class="p">(</span><span class="n">sampleStories</span><span class="p">())</span>

<span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Student invents electric motor to convert petrol and diesel cars into hybrids
LXD: Containers for Human Beings
The ViewSource Affordance
FAA authorizes Zipline to deliver commercial packages using drones
How to build a computer using origami
California hits Google for $93M over deceptive location data options
Clang-expand: Expand function invocations into current scope
ChatGPT and DALL-E 3 [video]
Harness launches Gitness, an open-source GitHub competitor
SQL Join Flavors
How does HN get away with not requiring users to verify with an email?
Using the WordStar Diamond in 2023
</pre></div>
</div>
</div>
</div>
<p>Let’s see what VADER thinks about the sentiment of these titles.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">analyzeStories</span><span class="p">(</span><span class="n">stories</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;vader&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">analyzeSentiment</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">story</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">story</span><span class="p">[</span><span class="s1">&#39;sentiment&#39;</span><span class="p">][</span><span class="s1">&#39;vader&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>


<span class="n">analyzeStories</span><span class="p">(</span><span class="n">stories</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Student invents electric motor to convert petrol and diesel cars into hybrids ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
LXD: Containers for Human Beings ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
The ViewSource Affordance ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
FAA authorizes Zipline to deliver commercial packages using drones ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
How to build a computer using origami ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
California hits Google for $93M over deceptive location data options ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
Clang-expand: Expand function invocations into current scope ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.723, &#39;pos&#39;: 0.277, &#39;compound&#39;: 0.3182})
ChatGPT and DALL-E 3 [video] ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
Harness launches Gitness, an open-source GitHub competitor ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
SQL Join Flavors ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.476, &#39;pos&#39;: 0.524, &#39;compound&#39;: 0.296})
How does HN get away with not requiring users to verify with an email? ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0})
Using the WordStar Diamond in 2023 ({&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.676, &#39;pos&#39;: 0.324, &#39;compound&#39;: 0.34})
</pre></div>
</div>
</div>
</div>
<p>While this is easy enough to implement and might give us a general idea of the sentiment, what if we want to push things a little further?</p>
<p>What if we have more complex text to analyze or have content that VADER’s training doesn’t handle well?</p>
<p>We could train our own model, but that’s a lot of work.</p>
</section>
<section id="chatgpt">
<h2>ChatGPT<a class="headerlink" href="#chatgpt" title="Permalink to this heading">#</a></h2>
<p>ChatGPT is an LLM that makes use of GPT architecture combined with <a class="reference external" href="https://openai.com/research/instruction-following">Instruction Tuning</a> to follow instructions and generate text based on the prompts that we provide.</p>
<p>It’s training data includes a whole bunch of stuff that we’ve all posted on the Internet over the years, as well as lots of other content.</p>
<p>This vast trove of training data, combined with the flexibility provided by it’s architecture and tuning, gives ChatGPT an impressive ability to respond to our requests for many tasks without needing to be retrained or <a class="reference external" href="https://www.lakera.ai/insights/llm-fine-tuning-guide">fine-tuned</a> for a specific task.</p>
<section id="how-chatgpt-works">
<h3>How ChatGPT works<a class="headerlink" href="#how-chatgpt-works" title="Permalink to this heading">#</a></h3>
<p>In responding to our prompts, ChatGPT follows a similar process to the NLP workflow described above.</p>
<p>It breaks our prompts into tokens, predicts which tokens should logically follow the ones that we’ve provided, and returns that text.</p>
</section>
<section id="tokens">
<h3>Tokens<a class="headerlink" href="#tokens" title="Permalink to this heading">#</a></h3>
<p>Tokenization breaks text down into units of meaning, and just like the stemming/lemmatization that we discussed earlier, you’ll notice that words are often broken down into their roots and suffixes when tokenized by ChatGPT’s Byte Pair Encoding (<a class="reference external" href="https://en.wikipedia.org/wiki/Byte_pair_encoding">BPE</a>) tokenization algorithm, <a class="reference external" href="https://github.com/openai/tiktoken">tiktoken</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tiktoken</span>


<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># To get the tokeniser corresponding to a specific model in the OpenAI API:</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">encoding_for_model</span><span class="p">(</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>

    <span class="n">tokenized</span> <span class="o">=</span> <span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">tokenId</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="p">:</span>
        <span class="n">ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokenId</span><span class="p">)</span>
        <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">decode_single_token_bytes</span><span class="p">(</span><span class="n">tokenId</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>


<span class="n">statements</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;I love that movie.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;I hate that movie.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;I like that movie.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;I dislike that movie.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;I saw that movie.&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">statement</span> <span class="ow">in</span> <span class="n">statements</span><span class="p">:</span>
    <span class="p">(</span><span class="n">statementTokens</span><span class="p">,</span> <span class="n">statementIds</span><span class="p">)</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">statement</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">statementTokens</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">statementTokens</span><span class="p">)</span><span class="si">}</span><span class="s2"> tokens)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">statementIds</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;I&#39;, &#39; love&#39;, &#39; that&#39;, &#39; movie&#39;, &#39;.&#39;] (5 tokens)
[40, 3021, 430, 5818, 13]
---
[&#39;I&#39;, &#39; hate&#39;, &#39; that&#39;, &#39; movie&#39;, &#39;.&#39;] (5 tokens)
[40, 12491, 430, 5818, 13]
---
[&#39;I&#39;, &#39; like&#39;, &#39; that&#39;, &#39; movie&#39;, &#39;.&#39;] (5 tokens)
[40, 1093, 430, 5818, 13]
---
[&#39;I&#39;, &#39; dislike&#39;, &#39; that&#39;, &#39; movie&#39;, &#39;.&#39;] (5 tokens)
[40, 48969, 430, 5818, 13]
---
[&#39;I&#39;, &#39; saw&#39;, &#39; that&#39;, &#39; movie&#39;, &#39;.&#39;] (5 tokens)
[40, 5602, 430, 5818, 13]
---
</pre></div>
</div>
</div>
</div>
<p>We’ve wired the input below up to the same tokenizer function above. Type in some text and see how the tokenizer responds.</p>
<p>There’s also a great visualizer available at <a class="reference external" href="https://gpt-tokenizer.dev/">https://gpt-tokenizer.dev/</a>.</p>
<div class="cell tag_hide-input tag_thebe-init docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code cell is just used to display a widget</span>
<span class="c1"># that uses the tokenize function we created</span>
<span class="c1"># you can just ignore/collapse it if you would prefer</span>
<span class="n">configureModel</span><span class="p">(</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">tokenAnalysisWidget</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "4422606179d94e828f360efe5a85d1b1"}</script></div>
</div>
</section>
</section>
<section id="prompt-engineering">
<h2>Prompt engineering<a class="headerlink" href="#prompt-engineering" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Prompt_engineering">Prompt engineering</a> (or “prompting” if you are into the whole brevity thing) is the process of creating and testing instructions for the model (called “prompts”) to find the most concise set of instructions that will guide the model towards returning your desired results as often as possible while minimizing undesired output like <a class="reference external" href="https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)">hallucinations</a> and <a class="reference external" href="https://news.ycombinator.com/item?id=36949931">apologies</a>.</p>
<p>In general, each message you send and each response that you receive become part of the overall prompt for the next message, but there are strategies for managing a conversation’s memory in order to selectively exclude messages that might lead to the model getting off track if repeated often enough.</p>
<p>You can think of the overall conversation as a document of text - it can help to imagine it as something like a <a class="reference external" href="https://en.wikipedia.org/wiki/Screenplay">screenplay</a>.</p>
<p>There are various types of messages that make up this screenplay:</p>
<ul class="simple">
<li><p><strong>System</strong>: system messages are sort of like stage directions, they describe the overall parameters that the model should follow and provide any other context that the model might need to know about as the conversation continues</p></li>
<li><p><strong>User</strong>: user messages are the individual prompts that the user sends to the model</p></li>
<li><p><strong>Assistant</strong>: assistant messages are the responses the model generates to the user’s prompts</p></li>
</ul>
<section id="example-conversation-document">
<h3>Example conversation document<a class="headerlink" href="#example-conversation-document" title="Permalink to this heading">#</a></h3>
<p>The whole thing looks a bit like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>[System]
Assistant is a large language model trained by OpenAI.
Knowledge cutoff: 2021-09
Current date: 2023-08-17
Browsing: disabled

[User]
Who won the Super Bowl in 2022?

[Assistant]
I&#39;m sorry, but I don&#39;t have access to real-time information as my knowledge
was last updated in September 2021. To find out the winner of the Super Bowl
in 2022, I recommend checking a reliable sports news website, a sports app,
or conducting a quick internet search for the most up-to-date information.
</pre></div>
</div>
<p><strong>Note</strong>: There are also messages with the type <code class="docutils literal notranslate"><span class="pre">function</span></code> that indicate that the Assistant would like to take advantage of <a class="reference external" href="https://openai.com/blog/function-calling-and-other-api-updates">function calling</a> by asking the system to execute the function with the given name and pass it the given parameters, but for this demo, we’ll be ignoring those.</p>
</section>
<section id="basic-example">
<h3>Basic example<a class="headerlink" href="#basic-example" title="Permalink to this heading">#</a></h3>
<p>Here’s an example of a basic prompt we could use for seniment analysis:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BASIC_SYSTEM_PROMPT</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">You are VibeCheck, an advanced AI system for detecting the sentiment conveyed in user-generated text.</span>

<span class="s2">The user will provide you with a prompt, and you will respond with the sentiment of that prompt.</span>

<span class="s2">Do not include any punctuation and only use lower case letters.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="nd">@backoff</span><span class="o">.</span><span class="n">on_exception</span><span class="p">(</span><span class="n">backoff</span><span class="o">.</span><span class="n">expo</span><span class="p">,</span> <span class="n">openai</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">RateLimitError</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">basicChatGptSentiment</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">BASIC_SYSTEM_PROMPT</span><span class="p">}]</span>

    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">})</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">TEMPERATURE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s apply this to our Hacker News stories from earlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">OPENAI_API_KEY</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">sentiment</span> <span class="o">=</span> <span class="n">basicChatGptSentiment</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">]:</span>
            <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;basic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sentiment</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">story</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">sentiment</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please enter your OpenAI API key above and rerun this cell&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Student invents electric motor to convert petrol and diesel cars into hybrids (positive)
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">12</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="k">if</span> <span class="n">OPENAI_API_KEY</span><span class="p">:</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>     <span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<span class="ne">----&gt; </span><span class="mi">3</span>         <span class="n">sentiment</span> <span class="o">=</span> <span class="n">basicChatGptSentiment</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>         <span class="k">if</span> <span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">]:</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>             <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/backoff/_sync.py:105,</span> in <span class="ni">retry_exception.&lt;locals&gt;.retry</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">96</span> <span class="n">details</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span>     <span class="s2">&quot;target&quot;</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">98</span>     <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="n">args</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">101</span>     <span class="s2">&quot;elapsed&quot;</span><span class="p">:</span> <span class="n">elapsed</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">102</span> <span class="p">}</span>
<span class="g g-Whitespace">    </span><span class="mi">104</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">105</span>     <span class="n">ret</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">106</span> <span class="k">except</span> <span class="n">exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">107</span>     <span class="n">max_tries_exceeded</span> <span class="o">=</span> <span class="p">(</span><span class="n">tries</span> <span class="o">==</span> <span class="n">max_tries_value</span><span class="p">)</span>

<span class="nn">Cell In[11], line 16,</span> in <span class="ni">basicChatGptSentiment</span><span class="nt">(prompt, model)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">BASIC_SYSTEM_PROMPT</span><span class="p">}]</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">})</span>
<span class="ne">---&gt; </span><span class="mi">16</span> <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span>     <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span>     <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span>     <span class="n">temperature</span><span class="o">=</span><span class="n">TEMPERATURE</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25,</span> in <span class="ni">ChatCompletion.create</span><span class="nt">(cls, *args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span> <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">25</span>         <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span>     <span class="k">except</span> <span class="n">TryAgain</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span>         <span class="k">if</span> <span class="n">timeout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">start</span> <span class="o">+</span> <span class="n">timeout</span><span class="p">:</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153,</span> in <span class="ni">EngineAPIResource.create</span><span class="nt">(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)</span>
<span class="g g-Whitespace">    </span><span class="mi">127</span> <span class="nd">@classmethod</span>
<span class="g g-Whitespace">    </span><span class="mi">128</span> <span class="k">def</span> <span class="nf">create</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">129</span>     <span class="bp">cls</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">136</span>     <span class="o">**</span><span class="n">params</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">139</span>         <span class="n">deployment_id</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>         <span class="n">engine</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">150</span>         <span class="n">api_key</span><span class="p">,</span> <span class="n">api_base</span><span class="p">,</span> <span class="n">api_type</span><span class="p">,</span> <span class="n">api_version</span><span class="p">,</span> <span class="n">organization</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span>
<span class="g g-Whitespace">    </span><span class="mi">151</span>     <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">153</span>     <span class="n">response</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">api_key</span> <span class="o">=</span> <span class="n">requestor</span><span class="o">.</span><span class="n">request</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">154</span>         <span class="s2">&quot;post&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">155</span>         <span class="n">url</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">156</span>         <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">157</span>         <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">158</span>         <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">159</span>         <span class="n">request_id</span><span class="o">=</span><span class="n">request_id</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">160</span>         <span class="n">request_timeout</span><span class="o">=</span><span class="n">request_timeout</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">161</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">163</span>     <span class="k">if</span> <span class="n">stream</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span>         <span class="c1"># must be an iterator</span>
<span class="g g-Whitespace">    </span><span class="mi">165</span>         <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">OpenAIResponse</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/openai/api_requestor.py:288,</span> in <span class="ni">APIRequestor.request</span><span class="nt">(self, method, url, params, headers, files, stream, request_id, request_timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">277</span> <span class="k">def</span> <span class="nf">request</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">278</span>     <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">279</span>     <span class="n">method</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">286</span>     <span class="n">request_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">287</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">OpenAIResponse</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">OpenAIResponse</span><span class="p">]],</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="ne">--&gt; </span><span class="mi">288</span>     <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">request_raw</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">289</span>         <span class="n">method</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span>
<span class="g g-Whitespace">    </span><span class="mi">290</span>         <span class="n">url</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">291</span>         <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">292</span>         <span class="n">supplied_headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">293</span>         <span class="n">files</span><span class="o">=</span><span class="n">files</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">294</span>         <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">295</span>         <span class="n">request_id</span><span class="o">=</span><span class="n">request_id</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">296</span>         <span class="n">request_timeout</span><span class="o">=</span><span class="n">request_timeout</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">297</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">298</span>     <span class="n">resp</span><span class="p">,</span> <span class="n">got_stream</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpret_response</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">stream</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">299</span>     <span class="k">return</span> <span class="n">resp</span><span class="p">,</span> <span class="n">got_stream</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">api_key</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/openai/api_requestor.py:596,</span> in <span class="ni">APIRequestor.request_raw</span><span class="nt">(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">594</span>     <span class="n">_thread_context</span><span class="o">.</span><span class="n">session_create_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">595</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">596</span>     <span class="n">result</span> <span class="o">=</span> <span class="n">_thread_context</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">request</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">597</span>         <span class="n">method</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">598</span>         <span class="n">abs_url</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">599</span>         <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">600</span>         <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">601</span>         <span class="n">files</span><span class="o">=</span><span class="n">files</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">602</span>         <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">603</span>         <span class="n">timeout</span><span class="o">=</span><span class="n">request_timeout</span> <span class="k">if</span> <span class="n">request_timeout</span> <span class="k">else</span> <span class="n">TIMEOUT_SECS</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">604</span>         <span class="n">proxies</span><span class="o">=</span><span class="n">_thread_context</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">proxies</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">605</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">606</span> <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">Timeout</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">607</span>     <span class="k">raise</span> <span class="n">error</span><span class="o">.</span><span class="n">Timeout</span><span class="p">(</span><span class="s2">&quot;Request timed out: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="p">))</span> <span class="kn">from</span> <span class="nn">e</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/requests/sessions.py:589,</span> in <span class="ni">Session.request</span><span class="nt">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>
<span class="g g-Whitespace">    </span><span class="mi">584</span> <span class="n">send_kwargs</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">    </span><span class="mi">585</span>     <span class="s2">&quot;timeout&quot;</span><span class="p">:</span> <span class="n">timeout</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">586</span>     <span class="s2">&quot;allow_redirects&quot;</span><span class="p">:</span> <span class="n">allow_redirects</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">587</span> <span class="p">}</span>
<span class="g g-Whitespace">    </span><span class="mi">588</span> <span class="n">send_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">settings</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">589</span> <span class="n">resp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">prep</span><span class="p">,</span> <span class="o">**</span><span class="n">send_kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">591</span> <span class="k">return</span> <span class="n">resp</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/requests/sessions.py:703,</span> in <span class="ni">Session.send</span><span class="nt">(self, request, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">700</span> <span class="n">start</span> <span class="o">=</span> <span class="n">preferred_clock</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">702</span> <span class="c1"># Send the request</span>
<span class="ne">--&gt; </span><span class="mi">703</span> <span class="n">r</span> <span class="o">=</span> <span class="n">adapter</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">request</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">705</span> <span class="c1"># Total elapsed time of the request (approximately)</span>
<span class="g g-Whitespace">    </span><span class="mi">706</span> <span class="n">elapsed</span> <span class="o">=</span> <span class="n">preferred_clock</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/requests/adapters.py:486,</span> in <span class="ni">HTTPAdapter.send</span><span class="nt">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="g g-Whitespace">    </span><span class="mi">483</span>     <span class="n">timeout</span> <span class="o">=</span> <span class="n">TimeoutSauce</span><span class="p">(</span><span class="n">connect</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">read</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">485</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">486</span>     <span class="n">resp</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">487</span>         <span class="n">method</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">488</span>         <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">489</span>         <span class="n">body</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">body</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">490</span>         <span class="n">headers</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">491</span>         <span class="n">redirect</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">492</span>         <span class="n">assert_same_host</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">493</span>         <span class="n">preload_content</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">494</span>         <span class="n">decode_content</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">495</span>         <span class="n">retries</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_retries</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">496</span>         <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">497</span>         <span class="n">chunked</span><span class="o">=</span><span class="n">chunked</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">498</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">500</span> <span class="k">except</span> <span class="p">(</span><span class="n">ProtocolError</span><span class="p">,</span> <span class="ne">OSError</span><span class="p">)</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span>     <span class="k">raise</span> <span class="ne">ConnectionError</span><span class="p">(</span><span class="n">err</span><span class="p">,</span> <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/urllib3/connectionpool.py:790,</span> in <span class="ni">HTTPConnectionPool.urlopen</span><span class="nt">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">787</span> <span class="n">response_conn</span> <span class="o">=</span> <span class="n">conn</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">release_conn</span> <span class="k">else</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">789</span> <span class="c1"># Make the request on the HTTPConnection object</span>
<span class="ne">--&gt; </span><span class="mi">790</span> <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_request</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">791</span>     <span class="n">conn</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">792</span>     <span class="n">method</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">793</span>     <span class="n">url</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">794</span>     <span class="n">timeout</span><span class="o">=</span><span class="n">timeout_obj</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">795</span>     <span class="n">body</span><span class="o">=</span><span class="n">body</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">796</span>     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">797</span>     <span class="n">chunked</span><span class="o">=</span><span class="n">chunked</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">798</span>     <span class="n">retries</span><span class="o">=</span><span class="n">retries</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">799</span>     <span class="n">response_conn</span><span class="o">=</span><span class="n">response_conn</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">800</span>     <span class="n">preload_content</span><span class="o">=</span><span class="n">preload_content</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">801</span>     <span class="n">decode_content</span><span class="o">=</span><span class="n">decode_content</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">802</span>     <span class="o">**</span><span class="n">response_kw</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">803</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">805</span> <span class="c1"># Everything went great!</span>
<span class="g g-Whitespace">    </span><span class="mi">806</span> <span class="n">clean_exit</span> <span class="o">=</span> <span class="kc">True</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/urllib3/connectionpool.py:536,</span> in <span class="ni">HTTPConnectionPool._make_request</span><span class="nt">(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)</span>
<span class="g g-Whitespace">    </span><span class="mi">534</span> <span class="c1"># Receive the response from the server</span>
<span class="g g-Whitespace">    </span><span class="mi">535</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">536</span>     <span class="n">response</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">getresponse</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">537</span> <span class="k">except</span> <span class="p">(</span><span class="n">BaseSSLError</span><span class="p">,</span> <span class="ne">OSError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">538</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_raise_timeout</span><span class="p">(</span><span class="n">err</span><span class="o">=</span><span class="n">e</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">timeout_value</span><span class="o">=</span><span class="n">read_timeout</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/urllib3/connection.py:461,</span> in <span class="ni">HTTPConnection.getresponse</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">458</span> <span class="kn">from</span> <span class="nn">.response</span> <span class="kn">import</span> <span class="n">HTTPResponse</span>
<span class="g g-Whitespace">    </span><span class="mi">460</span> <span class="c1"># Get the response from http.client.HTTPConnection</span>
<span class="ne">--&gt; </span><span class="mi">461</span> <span class="n">httplib_response</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">getresponse</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">463</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">464</span>     <span class="n">assert_header_parsing</span><span class="p">(</span><span class="n">httplib_response</span><span class="o">.</span><span class="n">msg</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/http/client.py:1378,</span> in <span class="ni">HTTPConnection.getresponse</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1376</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1377</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1378</span>         <span class="n">response</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1379</span>     <span class="k">except</span> <span class="ne">ConnectionError</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1380</span>         <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/http/client.py:318,</span> in <span class="ni">HTTPResponse.begin</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">316</span> <span class="c1"># read until we get a non-100 response</span>
<span class="g g-Whitespace">    </span><span class="mi">317</span> <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">318</span>     <span class="n">version</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">reason</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_status</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">319</span>     <span class="k">if</span> <span class="n">status</span> <span class="o">!=</span> <span class="n">CONTINUE</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">320</span>         <span class="k">break</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/http/client.py:279,</span> in <span class="ni">HTTPResponse._read_status</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">278</span> <span class="k">def</span> <span class="nf">_read_status</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">279</span>     <span class="n">line</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">readline</span><span class="p">(</span><span class="n">_MAXLINE</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;iso-8859-1&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">280</span>     <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">_MAXLINE</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">281</span>         <span class="k">raise</span> <span class="n">LineTooLong</span><span class="p">(</span><span class="s2">&quot;status line&quot;</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/socket.py:706,</span> in <span class="ni">SocketIO.readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">704</span> <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">705</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">706</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sock</span><span class="o">.</span><span class="n">recv_into</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">707</span>     <span class="k">except</span> <span class="n">timeout</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">708</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_timeout_occurred</span> <span class="o">=</span> <span class="kc">True</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/ssl.py:1311,</span> in <span class="ni">SSLSocket.recv_into</span><span class="nt">(self, buffer, nbytes, flags)</span>
<span class="g g-Whitespace">   </span><span class="mi">1307</span>     <span class="k">if</span> <span class="n">flags</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1308</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1309</span>           <span class="s2">&quot;non-zero flags not allowed in calls to recv_into() on </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
<span class="g g-Whitespace">   </span><span class="mi">1310</span>           <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1311</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">nbytes</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1312</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1313</span>     <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">recv_into</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="n">flags</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/ssl.py:1167,</span> in <span class="ni">SSLSocket.read</span><span class="nt">(self, len, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1165</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1166</span>     <span class="k">if</span> <span class="n">buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1167</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sslobj</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1168</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1169</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sslobj</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="going-further">
<h3>Going further<a class="headerlink" href="#going-further" title="Permalink to this heading">#</a></h3>
<p>What if we wanted to dig a bit deeper and consider the emotions that might be associated with some text rather than just a simple positive to negative spectrum?</p>
<p>In the traditional NLP approach, there were tools like <a class="reference external" href="https://pypi.org/project/nrclex/">NRCLex</a> that could help us with this, too.</p>
<p>Let’s explore how we could analyze the emotional content of some text with <code class="docutils literal notranslate"><span class="pre">nrclex</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nrclex</span> <span class="kn">import</span> <span class="n">NRCLex</span>


<span class="k">def</span> <span class="nf">getNRCEmotion</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">emotion</span> <span class="o">=</span> <span class="n">NRCLex</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">emotion</span><span class="o">.</span><span class="n">top_emotions</span>


<span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">emotions</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">emotionAnalysis</span> <span class="o">=</span> <span class="n">getNRCEmotion</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">emotion</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">emotionAnalysis</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mf">0.00</span><span class="p">:</span>
            <span class="n">emotions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">emotion</span><span class="p">)</span>

    <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;nrclex&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">emotions</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">story</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">emotions</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39;)&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">emotions</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>But, with how short some of our titles can be, it doesn’t always seem to get good results and it seems like sometimes it disagrees with the VADER sentiment analysis.</p>
<p>Luckily, we can pretty easily adapt our initial prompt to get ChatGPT to do this for us, too.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ADVANCED_SYSTEM_PROMPT</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">You are VibeCheck, an advanced AI system for detecting the sentiment conveyed in user-generated text.</span>

<span class="s2">The user will provide you with a prompt, and you will analyze it following these steps:</span>

<span class="s2">1. Analyze the prompt for relevant emotion, tone, affinity, sarcasm, irony, etc.</span>
<span class="s2">2. Analyze the likely emotional state of the author based on those findings</span>
<span class="s2">3. Summarize the emotional state and sentiment of the prompt based on your findings with at least 2, but no more than 5 names for emotions</span>

<span class="s2">Only return the output from the final step to the user.</span>

<span class="s2">Only respond with lowercase letters and separate each emotion with a comma and a space</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="nd">@backoff</span><span class="o">.</span><span class="n">on_exception</span><span class="p">(</span><span class="n">backoff</span><span class="o">.</span><span class="n">expo</span><span class="p">,</span> <span class="n">openai</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">RateLimitError</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">advancedChatGptSentiment</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">ADVANCED_SYSTEM_PROMPT</span><span class="p">}]</span>

    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">})</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">TEMPERATURE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s apply this to our Hacker News stories from earlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">OPENAI_API_KEY</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">sentiment</span> <span class="o">=</span> <span class="n">advancedChatGptSentiment</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">]:</span>
            <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;advanced&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sentiment</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">story</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">sentiment</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please enter your OpenAI API key above and rerun this cell&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="comparison-of-tools">
<h2>Comparison of tools<a class="headerlink" href="#comparison-of-tools" title="Permalink to this heading">#</a></h2>
<p>The widget below will allow you to enter arbitrary text and analyze it using the VADER sentiment analysis function from above, the NRCLex emotional analysis function from above, and the ChatGPT emotion analysis prompt we just created.</p>
<p>Play around with it and see how our various tools respond.</p>
<div class="cell tag_hide-input tag_thebe-init docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code cell is just used to display a widget</span>
<span class="c1"># that uses the analyzeSentiment function we created</span>
<span class="c1"># as well as the advancedChatGptSentiment function</span>
<span class="c1"># you can just ignore/collapse it if you would prefer</span>
<span class="n">configureOpenAi</span><span class="p">(</span><span class="n">OPENAI_API_KEY</span><span class="p">,</span> <span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">TEMPERATURE</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">advancedAnalysisWidget</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="beyond-sentiment">
<h2>Beyond sentiment<a class="headerlink" href="#beyond-sentiment" title="Permalink to this heading">#</a></h2>
<p>What if we were looking to do something a little more complicated than just basic sentiment or emotion analysis?</p>
<p>What if we wanted to describe the sentiment of some text via an emoji?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">EMOJI_SYSTEM_PROMPT</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">You are VibeCheck, an advanced AI system for detecting the sentiment conveyed in user-generated text.</span>

<span class="s2">The user will provide you with a prompt, and you will analyze it following these steps:</span>

<span class="s2">1. Analyze the prompt for relevant emotion, tone, affinity, sarcasm, irony, etc.</span>
<span class="s2">2. Analyze the likely emotional state of the author based on those findings</span>
<span class="s2">3. Summarize the emotional state and sentiment of the prompt based on your findings with at least 2, but no more than 5 names for emotions</span>
<span class="s2">4. Convert each of the emotional states you identified into a representative emoji or summarize the overall collection of states with a single emoji if there is one that captures it well</span>

<span class="s2">Only return the output from the final step to the user.</span>

<span class="s2">Only repsond with emojis.</span>
<span class="s2">&quot;&quot;&quot;</span>


<span class="nd">@backoff</span><span class="o">.</span><span class="n">on_exception</span><span class="p">(</span><span class="n">backoff</span><span class="o">.</span><span class="n">expo</span><span class="p">,</span> <span class="n">openai</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">RateLimitError</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">emojiChatGptSentiment</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">EMOJI_SYSTEM_PROMPT</span><span class="p">}]</span>

    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">})</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">TEMPERATURE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s apply this to our Hacker News stories from earlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">OPENAI_API_KEY</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">sentiment</span> <span class="o">=</span> <span class="n">emojiChatGptSentiment</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">]:</span>
            <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;emoji&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sentiment</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">story</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">sentiment</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please enter your OpenAI API key above and rerun this cell&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="prompting-strategies">
<h2>Prompting strategies<a class="headerlink" href="#prompting-strategies" title="Permalink to this heading">#</a></h2>
<p>In the previous examples we’ve been using <a class="reference external" href="https://www.promptingguide.ai/techniques/zeroshot">Zero Shot</a> prompting, which means we’re asking the model to repsond without giving it an example of what kind of response we’d like for it to have.</p>
<p>There are other prompting strategies we can employ, though:</p>
<ul class="simple">
<li><p><strong>One Shot</strong>: gives the model a single example of how we’d like it to respond to guide it’s output; this is useful for situations where the model needs a little guidance, but we don’t wnat to interfere with how it performs on other tasks</p></li>
<li><p><a class="reference external" href="https://www.promptingguide.ai/techniques/fewshot"><strong>Few Shot</strong></a>: gives the model a few examples of how we’d like it to respond to different prompts to help guide it’s output; this is useful for situations where the model is doing something novel and needs more guidance, and we’re going to be mostly focusing on asking the model to perform the task that we’re providing examples for</p></li>
</ul>
<p><strong>Note</strong>: For other types of tasks there are various prompting strategies that can be useful, like <a class="reference external" href="https://www.promptingguide.ai/techniques/cot">Chain of Thought Reasoning</a>, <a class="reference external" href="https://www.promptingguide.ai/techniques/dsp">Directional Stimulus Prompting</a>, and even telling the model to <a class="reference external" href="https://arstechnica.com/information-technology/2023/09/telling-ai-model-to-take-a-deep-breath-causes-math-scores-to-soar-in-study/">take a deep breath</a> can help it do math.</p>
<section id="learn-more-about-prompting-strategies">
<h3>Learn more about prompting strategies<a class="headerlink" href="#learn-more-about-prompting-strategies" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.promptingguide.ai/">Prompt Engineering Guide</a></p></li>
<li><p><a class="reference external" href="https://www.promptengineering.org/master-prompting-concepts-zero-shot-and-few-shot-prompting/">Master Prompting Concepts: Zero-Shot and Few-Shot Prompting</a></p></li>
<li><p><a class="reference external" href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/">ChatGPT Prompt Engineering Tips: Zero, One and Few Shot Prompting</a></p></li>
<li><p><a class="reference external" href="https://cloud.google.com/blog/products/application-development/five-best-practices-for-prompt-engineering">Tips to enhance your prompt-engineering abilities</a></p></li>
</ul>
</section>
<section id="one-shot-prompting">
<h3>One shot prompting<a class="headerlink" href="#one-shot-prompting" title="Permalink to this heading">#</a></h3>
<p>Providing a single example of the desired output can help with things like proper formatting and refine the quality of the model’s output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Grabbed from https://news.ycombinator.com/ at 2023-09-20 13:00 EDT</span>
<span class="c1"># Reference: https://news.ycombinator.com/item?id=37598299</span>
<span class="n">ONE_SHOT_USER_EXAMPLE</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;Cisco pulled out of the SentinelOne acquisition after due dilligence&quot;</span>
<span class="p">)</span>

<span class="n">ONE_SHOT_BOT_EXAMPLE</span> <span class="o">=</span> <span class="s2">&quot;🤨&quot;</span>


<span class="nd">@backoff</span><span class="o">.</span><span class="n">on_exception</span><span class="p">(</span><span class="n">backoff</span><span class="o">.</span><span class="n">expo</span><span class="p">,</span> <span class="n">openai</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">RateLimitError</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">oneShotChatGptSentiment</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">EMOJI_SYSTEM_PROMPT</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">ONE_SHOT_USER_EXAMPLE</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">ONE_SHOT_BOT_EXAMPLE</span><span class="p">},</span>
    <span class="p">]</span>

    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">})</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">TEMPERATURE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s apply this to our Hacker News stories from earlier and see how it changes the results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">OPENAI_API_KEY</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">sentiment</span> <span class="o">=</span> <span class="n">oneShotChatGptSentiment</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">]:</span>
            <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;oneshot&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sentiment</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">story</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">sentiment</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please enter your OpenAI API key above and rerun this cell&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="few-shot-prompting">
<h3>Few shot prompting<a class="headerlink" href="#few-shot-prompting" title="Permalink to this heading">#</a></h3>
<p>Providing a few examples of desired responses can give the model a chance to learn how you’d like it to respond.</p>
<p><strong>Note</strong>: Few shot prompting can also lead to issues where the model doesn’t respond as creatively or won’t perform as well on other tasks, which can be great for certain use cases, but might require a higher temperature setting for others.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Grabbed from https://news.ycombinator.com/ at 2023-09-20 13:10 EDT</span>
<span class="n">FEW_SHOT_USER_EXAMPLES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ONE_SHOT_USER_EXAMPLE</span><span class="p">,</span>
    <span class="c1"># Reference: https://news.ycombinator.com/item?id=37595898</span>
    <span class="s2">&quot;Atlassian cripples Jira automation for all but enterprise customers&quot;</span><span class="p">,</span>
    <span class="c1"># Reference: https://news.ycombinator.com/item?id=37586264</span>
    <span class="s2">&quot;Toyota Research claims breakthrough in teaching robots new behaviors&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">FEW_SHOT_BOT_EXAMPLES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ONE_SHOT_BOT_EXAMPLE</span><span class="p">,</span>
    <span class="s2">&quot;😖&quot;</span><span class="p">,</span>
    <span class="s2">&quot;👏&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="nd">@backoff</span><span class="o">.</span><span class="n">on_exception</span><span class="p">(</span><span class="n">backoff</span><span class="o">.</span><span class="n">expo</span><span class="p">,</span> <span class="n">openai</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">RateLimitError</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fewShotChatGptSentiment</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">EMOJI_SYSTEM_PROMPT</span><span class="p">}]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">userExample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">FEW_SHOT_USER_EXAMPLES</span><span class="p">):</span>
        <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">userExample</span><span class="p">})</span>
        <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">FEW_SHOT_BOT_EXAMPLES</span><span class="p">[</span><span class="n">i</span><span class="p">]})</span>

    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">})</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">TEMPERATURE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s apply this to our Hacker News stories from earlier and see how it changes the results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">OPENAI_API_KEY</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">sentiment</span> <span class="o">=</span> <span class="n">fewShotChatGptSentiment</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">]:</span>
            <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;fewshot&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sentiment</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">story</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">sentiment</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please enter your OpenAI API key above and rerun this cell&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="comparing-approaches">
<h2>Comparing approaches<a class="headerlink" href="#comparing-approaches" title="Permalink to this heading">#</a></h2>
<p>We’ve looked at various approaches to analyzing sentiment and explored some interesting and novel ways that we can work with AI models like ChatGPT to perform tasks that used to require large investments of time to gather and label data and then train a model.</p>
<p>Let’s compare the results of each analysis.</p>
<section id="gathering-our-data">
<h3>Gathering our data<a class="headerlink" href="#gathering-our-data" title="Permalink to this heading">#</a></h3>
<p>We’ll start by mapping our data into a format that is easier to display with <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html">DataFrames</a> provided by the <a class="reference external" href="https://pandas.pydata.org/"><code class="docutils literal notranslate"><span class="pre">pandas</span></code></a> library.</p>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this cell is used to gather our data into an object that&#39;s easier to work with</span>
<span class="c1"># when displaying some dataframes with slices of what we&#39;ve explored</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">sentimentData</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Story&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;VADER&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;NRC&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;ChatGPT (Sentiment)&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;ChatGPT (Emotion)&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;Zero Shot&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;One Shot&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;Few Shot&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="p">}</span>

<span class="k">for</span> <span class="n">storyId</span><span class="p">,</span> <span class="n">story</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="s2">&quot;title&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">:</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;Story&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>

    <span class="k">if</span> <span class="s2">&quot;vader&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">]:</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;VADER&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;vader&quot;</span><span class="p">])</span>

    <span class="k">if</span> <span class="s2">&quot;nrclex&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">]:</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;NRC&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;nrclex&quot;</span><span class="p">])</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="s2">&quot;openai&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">]</span>
        <span class="ow">and</span> <span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="s2">&quot;basic&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]:</span>
            <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;ChatGPT (Sentiment)&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;basic&quot;</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;advanced&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]:</span>
            <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;ChatGPT (Emotion)&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;advanced&quot;</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;emoji&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]:</span>
            <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;Zero Shot&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;emoji&quot;</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;oneshot&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]:</span>
            <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;One Shot&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;oneshot&quot;</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;fewshot&quot;</span> <span class="ow">in</span> <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">]:</span>
            <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;Few Shot&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">story</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">][</span><span class="s2">&quot;openai&quot;</span><span class="p">][</span><span class="n">modelDropdown</span><span class="o">.</span><span class="n">value</span><span class="p">][</span><span class="s2">&quot;fewshot&quot;</span><span class="p">]</span>
            <span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="sentiment-analysis">
<h3>Sentiment analysis<a class="headerlink" href="#sentiment-analysis" title="Permalink to this heading">#</a></h3>
<p>First let’s compare the VADER sentiment analysis to our basic ChatGPT sentiment analysis prompt.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this cell is only used to display a dataframe of our sentiment analysis results</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">checkArrayLengths</span><span class="p">(</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;Story&quot;</span><span class="p">],</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;VADER&quot;</span><span class="p">],</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;ChatGPT (Sentiment)&quot;</span><span class="p">],</span>
    <span class="p">):</span>
        <span class="n">sentimentDataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">sentimentData</span><span class="p">,</span>
            <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Story&quot;</span><span class="p">,</span> <span class="s2">&quot;VADER&quot;</span><span class="p">,</span> <span class="s2">&quot;ChatGPT (Sentiment)&quot;</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="n">display</span><span class="p">(</span>
            <span class="n">sentimentDataFrame</span>
            <span class="k">if</span> <span class="n">STORY_SAMPLE_SIZE</span> <span class="o">&lt;=</span> <span class="n">DATAFRAME_LIMIT</span>
            <span class="k">else</span> <span class="n">sentimentDataFrame</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">DATAFRAME_LIMIT</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Error: Different number of stories and sentiment results. Please rerun the VADER, Basic ChatGPT Example, and Gathering Our Data cells above and then rerun this cell.&quot;</span>
        <span class="p">)</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;Error: No sentiment data to display. Please rerun the Gathering Our Data cell above and then rerun this cell.&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="emotion-analysis">
<h3>Emotion analysis<a class="headerlink" href="#emotion-analysis" title="Permalink to this heading">#</a></h3>
<p>Next let’s compare the emotional analysis of NRCLex to our ChatGPT emotional analysis prompt.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code cell is only used to display a dataframe with our emotional analysis results</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">checkArrayLengths</span><span class="p">(</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;Story&quot;</span><span class="p">],</span> <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;NRC&quot;</span><span class="p">],</span> <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;ChatGPT (Emotion)&quot;</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="n">emotionDataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">sentimentData</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Story&quot;</span><span class="p">,</span> <span class="s2">&quot;NRC&quot;</span><span class="p">,</span> <span class="s2">&quot;ChatGPT (Emotion)&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># often NRCLex will not have data and instead of displaying NaN we&#39;ll leave it blank</span>
        <span class="n">emotionDataFrame</span> <span class="o">=</span> <span class="n">emotionDataFrame</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="n">display</span><span class="p">(</span>
            <span class="n">emotionDataFrame</span>
            <span class="k">if</span> <span class="n">STORY_SAMPLE_SIZE</span> <span class="o">&lt;=</span> <span class="n">DATAFRAME_LIMIT</span>
            <span class="k">else</span> <span class="n">emotionDataFrame</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">DATAFRAME_LIMIT</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Error: Different number of stories and sentiment results. Please rerun the NRCLex, Advanced ChatGPT Example, and Gathering Our Data cells above and then rerun this cell.&quot;</span>
        <span class="p">)</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;Error: No emotion data to display. Please rerun the Gathering Our Data cell above and then rerun this cell.&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="id1">
<h3>Prompting strategies<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>Finally, let’s compare the zero shot, one shot, and few shot approaches to our emoji analyzer.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this cell is just used to display a dataframe with our emoji results</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">checkArrayLengths</span><span class="p">(</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;Story&quot;</span><span class="p">],</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;Zero Shot&quot;</span><span class="p">],</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;One Shot&quot;</span><span class="p">],</span>
        <span class="n">sentimentData</span><span class="p">[</span><span class="s2">&quot;Few Shot&quot;</span><span class="p">],</span>
    <span class="p">):</span>
        <span class="n">emojiDataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">sentimentData</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Story&quot;</span><span class="p">,</span> <span class="s2">&quot;Zero Shot&quot;</span><span class="p">,</span> <span class="s2">&quot;One Shot&quot;</span><span class="p">,</span> <span class="s2">&quot;Few Shot&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">display</span><span class="p">(</span>
            <span class="n">emojiDataFrame</span>
            <span class="k">if</span> <span class="n">STORY_SAMPLE_SIZE</span> <span class="o">&lt;=</span> <span class="n">DATAFRAME_LIMIT</span>
            <span class="k">else</span> <span class="n">emojiDataFrame</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">DATAFRAME_LIMIT</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Error: Different number of stories and emoji results. Please rerun the Emjoji Classifier, One Shot, Few Shot, and Gathering Our Data cells above and then rerun this cell.&quot;</span>
        <span class="p">)</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;Error: No emoji data to display. Please rerun the Gathering Our Data cell above and then rerun this cell.&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h2>
<p>NLP tasks like sentiment analyis used to required significant resources and time, but with the advent of LLMs like ChatGPT and the continued discovery of new prompting strategies to guide these models we can quickly perform complex NLP analyses and teach models to perform novel tasks.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ericrallen/sentiment-analysis-notebook",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-sentiment-analysis">What is sentiment analysis?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#initial-setup">Initial Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration">Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-sentiment-analysis-with-nltk">Simple sentiment analysis with NLTK</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How it works</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learn-more">Learn more</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language-models">Language models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-example">Real world example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt">ChatGPT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-chatgpt-works">How ChatGPT works</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokens">Tokens</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering">Prompt engineering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-conversation-document">Example conversation document</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-example">Basic example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#going-further">Going further</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-tools">Comparison of tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beyond-sentiment">Beyond sentiment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompting-strategies">Prompting strategies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learn-more-about-prompting-strategies">Learn more about prompting strategies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-shot-prompting">One shot prompting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#few-shot-prompting">Few shot prompting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-approaches">Comparing approaches</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gathering-our-data">Gathering our data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sentiment-analysis">Sentiment analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#emotion-analysis">Emotion analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Prompting strategies</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Eric Allen
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>