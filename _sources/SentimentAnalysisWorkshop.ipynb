{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8f29fd",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with ChatGPT\n",
    "\n",
    "Sentiment Analysis is sort of like the \"Hello, world!\" of Natural Language Processing (NLP), but luckily for us, it's a bit more fun than just echoing out a string.\n",
    "\n",
    "This notebook will guide you through analyzing sentiment with ChatGPT and discuss some of the differences between how you can approach this problem with a generative AI like ChatGPT versus how you might have approached this problem in the past.\n",
    "\n",
    "## What is sentiment analysis?\n",
    "\n",
    "Sentiment Analysis is a way of analyzing some text to determine if it's positive, negative, or neutral.\n",
    "\n",
    "This is the kind of thing that's pretty easy for a human who understands the language the text is written in, but it can be hard for a computer to really understand the underlying meaning behind the text.\n",
    "\n",
    "### Examples\n",
    "\n",
    "1. \"I saw that movie.\" - Neutral\n",
    "2. \"I love that movie.\" - Positive\n",
    "3. \"I hate that movie.\" - Negative\n",
    "\n",
    "## How do we analyze sentiment?\n",
    "\n",
    "We'll start with some housekeeping first by making sure that our dependencies are ready.\n",
    "\n",
    "For this demo, we'll start out by exploring a more traditional approach that uses the Python Natural Language Toolkit (NLTK) and then we'll see how our approach might change when we use ChatGPT via the OpenAI SDK instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "557e3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%pip install openai nltk ipywidgets numpy requests-cache\n",
    "\n",
    "# standard library\n",
    "import os\n",
    "import requests as request\n",
    "\n",
    "# data science\n",
    "import numpy as np\n",
    "\n",
    "# caching\n",
    "import requests_cache\n",
    "\n",
    "# traditional nlp\n",
    "import nltk\n",
    "\n",
    "# modern llm\n",
    "import openai\n",
    "\n",
    "# jupyter notebook widgets\n",
    "import ipywidgets as pywidgets\n",
    "\n",
    "# project-specific widgets\n",
    "from widgets.simple import simpleAnalysisWidget\n",
    "from widgets.config import modelDropdown, apiKeyInput, apiKeyUpdateButton\n",
    "from widgets.sample import sampleSizeSlider, sampleSizeWarningLabel\n",
    "from widgets.advanced import advancedAnalysisWidget, configureOpenAi\n",
    "\n",
    "# project-specific utilities\n",
    "from utils.obfuscate import obfuscateKey\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# we'll only request new responses during this session\n",
    "# if previous responses are more than 15 minutes old\n",
    "REQUEST_CACHE_EXPIRATION_SECONDS = 60 * 15\n",
    "\n",
    "STORY_SAMPLE_SIZE = 5\n",
    "\n",
    "# we'll cache our hacker news api requests for 30 minutes\n",
    "session = requests_cache.CachedSession('hackernews_cache', expire_after=REQUEST_CACHE_EXPIRATION_SECONDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59708fe",
   "metadata": {},
   "source": [
    "## Simple sentiment analysis with NLTK\n",
    "\n",
    "Let's take a look at a simple example of sentiment analysis with `nltk` and VADER.\n",
    "\n",
    "The `SentimentIntensityAnalyzer` returns an object with positive, negative, and neutral scores for the given text as well as a combined `compound` score computed from the other three.\n",
    "\n",
    "For this basic example, we're going to rely on the `compound` score and use a naive rating scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cec9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the VADER sentiment analyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# instantiate the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# analyze the sentiment of a string of text\n",
    "def analyzeSentiment(text):\n",
    "  if not text:\n",
    "    return('')\n",
    "\n",
    "  # use VADER to get the +/- sentiment of the string\n",
    "  sentiment = analyzer.polarity_scores(text)\n",
    "\n",
    "  # map the sentiment to a human readable label\n",
    "  if sentiment['compound'] >= 0.75:\n",
    "    return('Very Positive')\n",
    "  elif sentiment['compound'] >= 0.4:\n",
    "    return('Positive')\n",
    "  elif sentiment['compound'] >= 0.1:\n",
    "    return('Leaning Positive')\n",
    "  elif sentiment['compound'] <= -0.1 and sentiment['compound'] > -0.4:\n",
    "    return('Leaning Negative')\n",
    "  elif sentiment['compound'] <= -0.4 and sentiment['compound'] > -0.75:\n",
    "    return('Negative')\n",
    "  elif sentiment['compound'] <= -0.75:\n",
    "    return('Very Negative')\n",
    "  else:\n",
    "    return('Neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c621be",
   "metadata": {},
   "source": [
    "Now let's test this analyzer with some example strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94cc9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love that movie. (Positive)\n",
      "I hate that movie. (Negative)\n",
      "I like that movie. (Leaning Positive)\n",
      "I dislike that movie. (Leaning Negative)\n",
      "I saw that movie. (Neutral)\n"
     ]
    }
   ],
   "source": [
    "# some simple test statements for our analyzer\n",
    "statements = [\n",
    "  'I love that movie.',\n",
    "  'I hate that movie.',\n",
    "  'I like that movie.',\n",
    "  'I dislike that movie.',\n",
    "  'I saw that movie.',\n",
    "]\n",
    "\n",
    "for statement in statements:\n",
    "  print(f\"{statement} ({analyzeSentiment(statement)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6429f9",
   "metadata": {},
   "source": [
    "We've wired the input below up to the same analyzer function from above. Type in some text and see how the analyzer responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342011fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba9746877e54c55a449c3db2fd26b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Text(value='', placeholder='Type something'), Output()), layout=Layout(align_items='center', dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code cell is just used to display a widget\n",
    "# that uses the analyzeSentiment function we created\n",
    "display(simpleAnalysisWidget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bbf2a5",
   "metadata": {},
   "source": [
    "## How Sentiment Analysis Works\n",
    "\n",
    "Sentiment analysis, like most text analysis involves a multistep process:\n",
    "\n",
    "1. **Stemming / Lemmatization**: reduces the words in the text to their root forms to simplify comparison between different forms of the same words\n",
    "   1. **Stemming**: removes suffixes as an attempt to reduce words to their root forms\n",
    "   2. **Lemmatization**: uses a morphological analysis of words to reduce them to their root forms\n",
    "2. **Tokenization**: breaks the text into individual units of meaning called tokens\n",
    "3. **Vectorization**: converts the tokens into a id that can be used for comparison\n",
    "4. **Comparison**: compares the tokens to a known set of tokens to determine the sentiment\n",
    "\n",
    "In this case we're taking advantage of an existing model that has been trained to analyze sentiment in text. If we wanted to build our own from scratch, it would be a more complicated process and require training data to feed into the model.\n",
    "\n",
    "With the advent of Generative Pre-Trained Transformer (GPT) models like those that power ChatGPT, and other transformer models that have exploded in popularity since, we can leverage the powerful inference and predictive capabilities of these models to perform sentiment analysis without having to train our own model, and we can even leverage some prompting techniques to quickly teach the model how to perform more unique analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c607a30",
   "metadata": {},
   "source": [
    "## A more interesting example\n",
    "\n",
    "So, let's see how this works with text generated by other humans without knowing that we're trying to analyze the sentiment of their text.\n",
    "\n",
    "For this example, we'll pull in a random sample of `20` of the [top stories](https://github.com/HackerNews/API#new-top-and-best-stories) on [Hacker News](https://news.ycombinator.com/) and analyze the sentiment of each submission's title.\n",
    "\n",
    "You can run the cell below a few times to see different samples of the top stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a63d88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc24e2b04244cabb4dc5b49d7acba51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=5, continuous_update=False, description='Sample Size:', min=1), Label(value='Wa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampleSizeSlider.value = STORY_SAMPLE_SIZE\n",
    "\n",
    "def updateSampleSize(change):\n",
    "  global STORY_SAMPLE_SIZE\n",
    "  STORY_SAMPLE_SIZE = change['new']\n",
    "\n",
    "sampleSizeWidgetContainer = pywidgets.VBox([\n",
    "  sampleSizeSlider,\n",
    "  sampleSizeWarningLabel\n",
    "])\n",
    "\n",
    "sampleSizeSlider.observe(updateSampleSize, names='value')\n",
    "\n",
    "display(sampleSizeWidgetContainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e3462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Zero 99 (Neutral)\n",
      "Faster Sorting Beyond DeepMind’s AlphaDev (Neutral)\n",
      "Trends in Remote Employee Salaries (Neutral)\n",
      "We Are Not Sustainable (Neutral)\n",
      "Quantum Resistance and the Signal Protocol (Neutral)\n"
     ]
    }
   ],
   "source": [
    "# we'll use this Array to aggregate the story titles so we can loop through and analyze them\n",
    "storyTitles = []\n",
    "\n",
    "# we'll use the request cache session we created earlier to make sure that this response is fast\n",
    "# when the cell runs again - \n",
    "topStoryIdsRequest = session.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n",
    "\n",
    "if topStoryIdsRequest.status_code != 200:\n",
    "  print('There was a problem getting the top stories from Hacker News')\n",
    "  exit()\n",
    "\n",
    "topStoryIds = topStoryIdsRequest.json()\n",
    "\n",
    "storyIds = np.array(topStoryIds)[np.random.choice(len(topStoryIds), STORY_SAMPLE_SIZE, replace=False)]\n",
    "\n",
    "for storyId in storyIds:\n",
    "  # we'll use the same request cache so that we don't have to request a story's details more than once\n",
    "  storyRequest = session.get(f'https://hacker-news.firebaseio.com/v0/item/{storyId}.json')\n",
    "\n",
    "  if storyRequest.status_code != 200:\n",
    "    continue\n",
    "  else:\n",
    "    story = storyRequest.json()\n",
    "\n",
    "    if 'title' in story:\n",
    "      storyTitles.append(story['title'])\n",
    "\n",
    "# iterate through titles and analyze the sentiment\n",
    "for storyTitle in storyTitles:\n",
    "  print(f\"{storyTitle} ({analyzeSentiment(storyTitle)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d164653f",
   "metadata": {},
   "source": [
    "## How ChatGPT works\n",
    "\n",
    "Break down how ChatGPT turns text into tokens and then predicts the most likely tokens to follow the given text so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc95505",
   "metadata": {},
   "source": [
    "## Prompt engineering\n",
    "\n",
    "Describe prompt engineering and break down system, user, and assistant prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6a510",
   "metadata": {},
   "source": [
    "## Zero shot and few shot prompting\n",
    "\n",
    "Discuss the differences between few show and zero shot and give some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12db0c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32231df3494141c7b3e66e38caf2f899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Text(value='sk-I**********yeC3', description='OpenAI API Key', placeholder='Enter your OpenAI AP…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code cell is just used to display a widget\n",
    "# for us to configure the OpenAI API and to update\n",
    "# your API key if you need to change it\n",
    "apiKeyInput.value = obfuscateKey(OPENAI_API_KEY)\n",
    "\n",
    "def updateApiKey(event):\n",
    "  global OPENAI_API_KEY\n",
    "\n",
    "  # store the updated key in our global variable\n",
    "  OPENAI_API_KEY = apiKeyInput.value\n",
    "\n",
    "  # obfuscate the displayed key\n",
    "  apiKeyInput.value = obfuscateKey(OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "openAiConfigWidget = pywidgets.Box([apiKeyInput, apiKeyUpdateButton, modelDropdown], layout=pywidgets.Layout(display='flex', flex_direction='column', align_items='center', width='100%'))\n",
    "\n",
    "apiKeyUpdateButton.on_click(updateApiKey)\n",
    "\n",
    "display(openAiConfigWidget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c237a87",
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1694090931628,
     "user": {
      "displayName": "Matthias Kraft",
      "userId": "07587708083169164935"
     },
     "user_tz": -120
    },
    "id": "3c237a87"
   },
   "outputs": [],
   "source": [
    "BASIC_SYSTEM_PROMPT = \"\"\"\n",
    "You are SentiNet, an advanced AI system for detecting the sentiment conveyed in user-generated text.\n",
    "\n",
    "The user will provide you with a prompt, and you will respond with the sentiment of that prompt.\n",
    "\n",
    "Be concise.\n",
    "\"\"\"\n",
    "\n",
    "def basicChatGptSentiment(prompt, model=modelDropdown.value):\n",
    "    messages = [{ \"role\": \"system\", \"content\": BASIC_SYSTEM_PROMPT }]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0e406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Zero 99\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Neutral\n",
      "---\n",
      "Faster Sorting Beyond DeepMind’s AlphaDev\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Excitement\n",
      "---\n",
      "Trends in Remote Employee Salaries\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Neutral\n",
      "---\n",
      "We Are Not Sustainable\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Negative\n",
      "---\n",
      "Quantum Resistance and the Signal Protocol\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: Neutral\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "if OPENAI_API_KEY:\n",
    "  for storyTitle in storyTitles:\n",
    "    nltkSentiment = analyzeSentiment(storyTitle)\n",
    "    openAiSentiment = basicChatGptSentiment(storyTitle)\n",
    "\n",
    "    print(f\"{storyTitle}\\nNLTK: {nltkSentiment}\\n{modelDropdown.value}: {openAiSentiment}\\n---\")\n",
    "else:\n",
    "  print('Please enter your OpenAI API key above and rerun this cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e479fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADVANCED_SYSTEM_PROMPT = \"\"\"\n",
    "You are SentiNet, an advanced AI system for detecting the sentiment conveyed in user-generated text.\n",
    "\n",
    "The user will provide you with a prompt, and you will analyze it following these steps:\n",
    "\n",
    "1. Analyze the prompt for relevant emotion, tone, affinity, sarcasm, irony, etc.\n",
    "2. Analyze the likely emotional state of the author based on those findings from step 1\n",
    "3. Summarize the emotional state and sentiment of the prompt based on your findings using 5 or less names for emotions using lowercase letters and separating each emotional state with a comma\n",
    "\n",
    "Only return the output from the final step to the user.\n",
    "\n",
    "Be concise.\n",
    "\"\"\"\n",
    "\n",
    "def advancedChatGptSentiment(prompt, model=modelDropdown.value):\n",
    "    messages = [{ \"role\": \"system\", \"content\": ADVANCED_SYSTEM_PROMPT }]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.15,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd2aee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Zero 99\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: neutral\n",
      "---\n",
      "Faster Sorting Beyond DeepMind’s AlphaDev\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: neutral\n",
      "---\n",
      "Trends in Remote Employee Salaries\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: neutral\n",
      "---\n",
      "We Are Not Sustainable\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: negative\n",
      "---\n",
      "Quantum Resistance and the Signal Protocol\n",
      "NLTK: Neutral\n",
      "gpt-3.5-turbo: neutral\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "if OPENAI_API_KEY:\n",
    "  for storyTitle in storyTitles:\n",
    "    nltkSentiment = analyzeSentiment(storyTitle)\n",
    "    openAiSentiment = advancedChatGptSentiment(storyTitle)\n",
    "\n",
    "    print(f\"{storyTitle}\\nNLTK: {nltkSentiment}\\n{modelDropdown.value}: {openAiSentiment}\\n---\")\n",
    "else:\n",
    "  print('Please enter your OpenAI API key above and rerun this cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59daa29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534e37e6f6fc4410aa558dc19cd167e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value=\"Ukraine's counteroffensive has breached Russian defenses, but progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code cell is just used to display a widget\n",
    "# that uses the analyzeSentiment function we created\n",
    "# as well as the advancedChatGptSentiment function\n",
    "configureOpenAi(OPENAI_API_KEY, modelDropdown.value)\n",
    "\n",
    "display(advancedAnalysisWidget)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
